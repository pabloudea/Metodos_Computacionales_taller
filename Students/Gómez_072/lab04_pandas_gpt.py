# -*- coding: utf-8 -*-
"""Lab04_pandas_gpt.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VvEUlnYJa2IMqBOTM4QIXcnHhMCZiLQU

<a href="https://colab.research.google.com/github/hernansalinas/autogrades/blob/main/Laboratorios_Taller/Lab04_pandas_gpt.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>

>>>[Pandas y chat gpt](#scrollTo=TVI5i4Vbf_Hh)

>>>[Problema 1](#scrollTo=TVI5i4Vbf_Hh)

>>>[Problema 2.](#scrollTo=TVI5i4Vbf_Hh)

>>>[Problema 3](#scrollTo=TVI5i4Vbf_Hh)

>>>[Problema 4](#scrollTo=TVI5i4Vbf_Hh)

>[Trabajo en clase](#scrollTo=YeWda0wX8Ypo)

>[solucion](#scrollTo=evIEuW2-8VZg)

>>[Problema 1](#scrollTo=ubjhDNstxMS0)

>>[Problema 2.](#scrollTo=Y1gWRaNCOPiq)

### Pandas y chat gpt

Comandos basicos de pandas:


| Function | Description |
| --- | --- |
| `fillna()` | Replace NaN values in a DataFrame or Series with a specified value. |
| `dropna()` | Remove rows or columns containing NaN values from a DataFrame. |
| `loc[]` | Select rows and columns from a DataFrame by label-based indexing. |
| `iloc[]` | Select rows and columns from a DataFrame by integer-based indexing. |
| `[]` | Select a single column from a DataFrame using dot notation or bracket notation. |
| `shape` | Get the number of rows and columns in a DataFrame. |
| `dtypes` | Get the data types of the columns in a DataFrame. |
| `head()` | Get the first n rows of a DataFrame. |
| `tail()` | Get the last n rows of a DataFrame. |
| `describe()` | Get summary statistics for the columns in a DataFrame. |
| `groupby()` | Group a DataFrame by one or more columns and perform an aggregation. |
| `sort_values()` | Sort a DataFrame by one or more columns. |
| `merge()` | Merge two DataFrames on a common column. |
| `pivot_table()` | Create a pivot table from a DataFrame. |
| `to_csv()` | Save a DataFrame to a CSV file. |
| `read_csv()` | Read a CSV file into a DataFrame. |





### Problema 1
1. a) Generar un diccionario con CHATGPT con los premios nobel de fisica de la decada que tu elijas.  El diccionario debe tener la siguiente estructura:

clave: Nombre del cientifico, el nombre del cientifico se debe llamar de la siguiente forma: Inicial del nombre del cientifico y Apellido, ejemplo: A. Einstein., R. Feyman.

Valor: diccionario con el año y el motivo por que el gano el premio nobel resumido maximo 10 palabras.


b). Con el diccionario construir un dataframe de pandas y almacenarlo como un archivo csv. Las columnas del data frame se deberán llamar Cientifico, AnoNobel, Motivo. 




### Problema 2.

Usando el dataset `PS4_1.csv`, convertir la serie `Date` en el indice (serie de tiempo) y eliminar la serie `Unnamed: 1` (generado por pandas), retornar un  diccionario con en el siguiente orden:

* cantidad de columnas
* Nombre de las columnas
* número de registros no NaN de cada columna
* cantidad total de memoria usada para cargar el dataset en el computador ,( df.memory_usage() )
* Estadistica basica para cada columna, media, desviacion estandar, maximo
* Remplazar los NaN por None


```
import pandas as pd

df = pd.read_excel("dataset/PS4_1.xlsx")
for d in df.Date:
    if(type(d)==str):
        df["Date_"] = datetime.strptime(d, "%d/%m/%Y")
    else:
        df["Date_"]=d
df=df.set_index("Date_")
df=df.drop(columns=["Date","Unnamed: 1"])

```


### Problema 3

Realizar la lectura del data frame "Crimes_-_2019.csv" asociado a los crimenes que se presentaron en Chicago en el 2019. 


1. Ver la estadistica general del data frame.
2. Elimnar  las columnas PrimaryType, y Date.
3. Transformar la columna Date que es tipo string en una tipo Fecha, use el siguiente metodo de pandas pd.to_datetime(df.Date,format="%m/%d/%Y %I:%M:%S %p")
4. Mostrar los casos totales para cada tipo de crimen de forma ascendente, emplee:
   df.groupby(columna).Date.count()
   
   sort_values()
5. Ordenar los valores por orden alfabetico de Primary type
6. Mostrar de la fila 100 a la 120
6. Realizar una visualización de los datos anteriores.Emplee la libreria  seaborn con un grafico tipo barplot. Ej.
   ax = sns.barplot(x = "contador", y="Primary Type", data = datos)




### Problema 4

1. Leer el dataset country_vaccinations.csv  y filtrar los datos para Colombia
2. Crear un csv con los datos para colombia
3. Realizar una comparacion con los paises latinoamericanos de la cantidad de vacunados.
4. A traves de mascaras determinar el numero de vacunados en el intervalo  [1.5E6, 2.0E6]




Referencias: Puedes consultar la pagina kaggle para estudiar mas acerca de pandas

#Trabajo en clase
"""

#recomendación: generar un diccionario de python con clave, valor, donde la clave son los nombre de los fisicos que ganaron el premio novel entre 1980 y 1990, incluir en el valor del diccinario
#un diccionario con el año en que ganó y 10 plabras con el motivo

#por ejemplo dicc={"A.Einstein": {1905:'efecto fotoelectrico'}}

#el nomre escribirlo en la siguiente notacion: Iniciales del nombre. apellido


#se puede resumir un poco mas

import pandas as pd

dic= {'Exactas':'astronomia', 'Humanas':'sociologia', 'ingeniería':'alimentos', 'artes':'canto'}

#mostrar las claves

dic.keys()

#mostrar los valores

dic.values()

#iterar para mostrar clave, valor

for i,s in enumerate(dic):
  print(i,s, dic[s])       #la i corresponde al cero, uno, dos ; s son las claves;dic[s es el valor ascociado a cada una de las claves

#crear una serie a partir del diccionario

serie= pd.Series(dic)
serie

#acceder a los indices

serie.loc['Exactas'], serie.iloc[0]

serie.iloc[:]    #notamos que con iloc se accede por medio de indices, y loc se accede por medio de las claves

juan_class= pd.Series(['a', 'b', 'c'], index= ['letraaaa', '1', '2'])   #otra forma de definirlo sin necesidad de diccionarios --> yo disponog los indices
juan_class

d1= {'name': 'juan', 'topic': 'fisica mecanica', 'score': 5}
d2= {'name': 'pedro', 'topic': 'fisica cuantica', 'score': 3}
d3= {'name': 'francisco', 'topic': 'astronomia', 'score': 7}

r_1= pd.Series(d1)
r_2= pd.Series(d2)
r_3= pd.Series(d3)

df1= pd.DataFrame([r_1, r_2, r_3])
df1

pd.DataFrame([d1,d2,d3])   #se puede llear a lo mismo sin considerar las series, pero es importante tener en cuenta que es otra forma de construirlo

df1.name    #forma de acceder a las columnas

df1['name']   #otra forma de acceder a las columnas --> con estos elementos ya se puede hacer opeaciones entre las columnas

df1.name + ' ' + df1.topic    #una de las operciones que se pueden realizar

df1.iloc[0]     #para ubicar los elementos de la primera fila con sus respectivas categorías

df2= pd.DataFrame([r_1, r_2, r_3], index= ['udea', 'unal', 'MIT'])   #es una forma de cambiar los indices cero
df2

df2.loc['udea']   #accedo a los elementos de la fila con el indice que definí

fisicos_nobel = {
    'J. Cronin': {
        'año': 1980,
        'motivo': 'Descubrimiento de la violación de simetría CP en la desintegración de partículas elementales'
    },
    'B. Benacerraf': {
        'año': 1980,
        'motivo': 'Descubrimientos sobre las estructuras genéticas que controlan la respuesta inmunológica y el papel del sistema de histocompatibilidad'
    },
    'N. Cabrera': {
        'año': 1981,
        'motivo': 'Descubrimientos experimentales sobre el efecto túnel en superconductores débiles'
    },
    'K.G. Wilson': {
        'año': 1982,
        'motivo': 'Teoría de la renormalización y su aplicación a la física de la materia condensada, especialmente en relación con los efectos críticos de fenómenos de simetría rota'
    },
    'S. Chandrasekhar': {
        'año': 1983,
        'motivo': 'Estudios teóricos sobre las etapas finales de la evolución de las estrellas y las estructuras y procesos estelares'
    },
    'C. Rubbia': {
        'año': 1984,
        'motivo': 'Descubrimiento de las partículas W y Z que transmiten la fuerza débil'
    },
    'K. von Klitzing': {
        'año': 1985,
        'motivo': 'Descubrimiento del efecto cuántico Hall entero'
    },
    'E. Ruska': {
        'año': 1986,
        'motivo': 'Desarrollo de la microscopía electrónica de alta resolución'
    },
    'J.G. Bednorz': {
        'año': 1987,
        'motivo': 'Descubrimiento de la superconductividad a altas temperaturas en materiales cerámicos'
    },
    'A. Müller': {
        'año': 1987,
        'motivo': 'Descubrimiento de la superconductividad a altas temperaturas en materiales cerámicos'
    },
    'L.M. Lederman': {
        'año': 1988,
        'motivo': 'Descubrimiento del neutrino muonico'
    },
    'M. Schwartz': {
        'año': 1988,
        'motivo': 'Descubrimiento del neutrino muonico'
    },
    'J. Steinberger': {
        'año': 1988,
        'motivo': 'Descubrimiento del neutrino muonico'
    },
    'N. Bloembergen': {
        'año': 1981,
        'motivo': 'Desarrollo de la espectroscopía no lineal'
    },
    'Arthur Schawlow': {
        'año': 1981,
        'motivo': 'Desarrollo de la espectroscopía láser'
    },
    'Karl Alex Müller': {
        'año': 1987,
        'motivo': 'Descubrimiento de la superconductividad a altas temperaturas en materiales cerámicos'
    }
   }

import pandas as pd

df= pd.DataFrame(fisicos_nobel)
df

df.transpose()  #los nombres han quedado como el indice

g= df.transpose().reset_index().copy()   #reset index para que ya el nombre no quede como el indice   --- creo una copia y la almaceno en g para que no se modifique el original

g.columns

col=['científico', 'año', 'motivo']

g= g.rename(columns={'index':'científico', 'año':'año'})   #debo reasignar a g para que los cambios se vean reflejados
g

g.drop(['científico'], axis= 1)

#ponemos el enlace del archivo que hemos publicado en la web

url= 'https://docs.google.com/spreadsheets/d/e/2PACX-1vRR6Rko3svpDTswovIyNEcTfTEfhMS8N6lYaYrM78YfHV6PcGkcfFJypP50f_fojA/pub?output=xlsx'

df= pd.read_excel(url)
df

import datetime

df.Date[300],df.Date[0]   #los primeros son datetime, pero el resto no

for f in df.Date:
  print(type(f))

a= '27/12/2009'

pd.to_datetime(a)

"""#solucion

## Problema 1
1. a) Generar un diccionario con CHATGPT con los premios nobel de fisica de la decada que tu elijas.  El diccionario debe tener la siguiente estructura:

clave: Nombre del cientifico, el nombre del cientifico se debe llamar de la siguiente forma: Inicial del nombre del cientifico y Apellido, ejemplo: A. Einstein., R. Feyman.

Valor: diccionario con el año y el motivo por que el gano el premio nobel resumido maximo 10 palabras.


b). Con el diccionario construir un dataframe de pandas y almacenarlo como un archivo csv. Las columnas del data frame se deberán llamar Cientifico, AnoNobel, Motivo.
"""

#comenzamos por generar el diccionario por medio de chat gpt

dic = {
    'O. Stern': {
        'año': 1943,
        'motivo': 'momento magnético del protón'
    },
    'I. I. Rabi': {
        'año': 1944,
        'motivo': 'resonancia magnética de los núcleos atómicos'
    },
    'W. Pauli': {
        'año': 1945,
        'motivo': 'principio de exclusión para los electrones'
    },
    'P. W. Bridgman': {
        'año': 1946,
        'motivo': 'física de alta presión'
    },
    'E. V. Appleton': {
        'año': 1947,
        'motivo': 'investigaciones en la ionosfera'
    },
    'P. M. S. Blackett': {
        'año': 1948,
        'motivo': 'cámara de burbujas'
    },
    'H. Yukawa': {
        'año': 1949,
        'motivo': 'descubrimiento del mesón'
    },
    'C. F. Powell': {
        'año': 1950,
        'motivo': 'cámara de emulsiones'
    }
}

import pandas as pd

df = pd.DataFrame(dic)
df

#genero una copia en g, para que el dataframe original no se vea modificado

g= df.transpose().reset_index().copy()                 #quito el indice que por defecto lo generó como el nombre del científico
g

#vamos a cambiar el nombre de las columnas del dataframe anterior

g.columns = ['Científico', 'Año Nobel', 'Motivo']   
g


#esto mismo puedo hacerlo como:
# g= g.rename(columns={'index':'científico', 'año':'año'})       #lo reasigno a g para que los cambios se vean reflejados

#ahora, vamos a almacenar el anterior DataFrame como un archivo csv

g.to_csv('premios nobel entre 1940 y 1950.csv', index=False)

"""## Problema 2.

Usando el dataset `PS4_1.csv`, convertir la serie `Date` en el indice (serie de tiempo) y eliminar la serie `Unnamed: 1` (generado por pandas), retornar un  diccionario con en el siguiente orden:

* cantidad de columnas
* Nombre de las columnas
* número de registros no NaN de cada columna
* cantidad total de memoria usada para cargar el dataset en el computador ,( df.memory_usage() )
* Estadistica basica para cada columna, media, desviacion estandar, maximo
* Remplazar los NaN por None


```
import pandas as pd

df = pd.read_excel("dataset/PS4_1.xlsx")
for d in df.Date:
    if(type(d)==str):
        df["Date_"] = datetime.strptime(d, "%d/%m/%Y")
    else:
        df["Date_"]=d
df=df.set_index("Date_")
df=df.drop(columns=["Date","Unnamed: 1"])

```

"""

#ponemos el enlace del archivo que hemos publicado en la web

url= 'https://docs.google.com/spreadsheets/d/e/2PACX-1vRR6Rko3svpDTswovIyNEcTfTEfhMS8N6lYaYrM78YfHV6PcGkcfFJypP50f_fojA/pub?output=xlsx'

import pandas as pd

df= pd.read_excel(url)
df

#lo primero que vamos a hacer es convertir la columna date a una serie de tiempo --> de modo que quede como un datetime

import datetime

for d in df.Date:
  if type(d) == str:                 #hacemos esto porque algunos de los elementos que hay en la columna se encuentras como str y otros ya están directamnete en el formato apropiado
    df['Date_'] = datetime.datetime.strptime(d, '%d/%m/%Y')
  else:
    df['Date_'] = d

df = df.set_index('Date_')                        #hacemos que la fecha en el formato correcto quede como el indice
df = df.drop(columns = ['Date', 'Unnamed: 1'])    #eliminamos al columna que tiene la fecha en un formato inapropiado, y la columna que nos piden que eliminemos

type(df.index)

df

"""Comandos basicos de pandas:


| Function | Description |
| --- | --- |
| `fillna()` | Replace NaN values in a DataFrame or Series with a specified value. |
| `dropna()` | Remove rows or columns containing NaN values from a DataFrame. |
| `loc[]` | Select rows and columns from a DataFrame by label-based indexing. |
| `iloc[]` | Select rows and columns from a DataFrame by integer-based indexing. |
| `[]` | Select a single column from a DataFrame using dot notation or bracket notation. |
| `shape` | Get the number of rows and columns in a DataFrame. |
| `dtypes` | Get the data types of the columns in a DataFrame. |
| `head()` | Get the first n rows of a DataFrame. |
| `tail()` | Get the last n rows of a DataFrame. |
| `describe()` | Get summary statistics for the columns in a DataFrame. |
| `groupby()` | Group a DataFrame by one or more columns and perform an aggregation. |
| `sort_values()` | Sort a DataFrame by one or more columns. |
| `merge()` | Merge two DataFrames on a common column. |
| `pivot_table()` | Create a pivot table from a DataFrame. |
| `to_csv()` | Save a DataFrame to a CSV file. |
| `read_csv()` | Read a CSV file into a DataFrame. |
"""

#ahora, vamos a retornar diccionario con los elementos que nos piden:
#primero vamos a seleccionar los elementos que nos piden

#cantidad de columnas

columnas= df.shape[1]

#nombre de las columnas

name_cols = df.columns.tolist()           #convierto el nombre de las columnas que el atributo me da

#vamos ahora un código para ver el numero de registros no NaN de cada columna

no_NaN = []

for d in df.columns:
  numero =df[d].isna().sum()     #isna devuelve una mascarra booleana que indica que valores son NaN, el método sum suma los valores true de la máscara dada
  no_NaN.append(len(df[d]) - numero)   #imprimo 365 que es el numero de filas del dataframe, menos el numero de elemtnos no NaN que tiene cada una de las columnas

#numero de registros no NAN de cada columna

no_NaN      # notamos que en las tres primeras columnas no hay valores que sean NaN

#cantidad total de memoria usada para cargar el dataset en el computador:

memoria = df.memory_usage() 
memo_dic = memoria.to_dict()

#estadísticas básicas para cada columna

media=[]                               #miramos la media de cada una de las columnas
for i in range(4):
  media_cu= df[name_cols[i]].mean()
  media.append(media_cu)

desv_est =[]
for i in range(4):
  desv= df[name_cols[i]].std()
  desv_est.append(desv)

maximo= []
for i in range(4):
  max= df[name_cols[i]].max()
  maximo.append(max)

desv_est

#finalmente construimos el diccionario que contenga toda la información que hemos ido generando

dicc = {'Numero de Columnas' : columnas, 'Nombre de las columnas':name_cols, 
        'Numero de registros no NaN de cada columna':{name_cols[0] : no_NaN[0], name_cols[1] : no_NaN[1], name_cols[2] : no_NaN[2], name_cols[3] : no_NaN[3]},
        'Cantidad total de memoria usada para cargar el dataset en el computador': memo_dic,
        'Estadísticas básicas para cada columna': {name_cols[0]:{'media' : media[0], 'desviacion estándar' : desv_est[0], 'valor máximo' : maximo[0]},
                                                   name_cols[1]:{'media' : media[1], 'desviacion estándar' : desv_est[1], 'valor máximo' : maximo[1]},
                                                   name_cols[2]:{'media' : media[2], 'desviacion estándar' : desv_est[2], 'valor máximo' : maximo[2]},
                                                   name_cols[3]:{'media' : media[3], 'desviacion estándar' : desv_est[3], 'valor máximo' : maximo[3]} } }

dicc

#el anterior diccionario fue diseñado por mi, y con la ayuda de chat gpt se ha convertido en un dataframe

columns = dicc['Nombre de las columnas']
n_non_nan = pd.Series(dicc['Numero de registros no NaN de cada columna'])
mem_usage = pd.Series(dicc['Cantidad total de memoria usada para cargar el dataset en el computador'])
stats = pd.DataFrame(dicc['Estadísticas básicas para cada columna']).transpose()

# Combine data into a single dataframe
df_ = pd.concat([n_non_nan, stats, mem_usage], axis=1)
df_.columns = ['Non-NaN Records', 'Mean', 'Std Dev', 'Max Value', 'Memory Usage']
df_.index.name = 'Column'
df_ = df_.reset_index()
#df['Column'] = df['Column'].apply(lambda x: columns.index(x) + 1)
df_ = df_[['Column', 'Non-NaN Records', 'Mean', 'Std Dev', 'Max Value', 'Memory Usage']]

df_

#por ultimo, debemos reemplazar los NaN por None

g= df.fillna('None')     #generamos un nuevo DataFrame con la corrección que se pide
g

"""## Problema 3

Realizar la lectura del data frame "Crimes_-_2019.csv" asociado a los crimenes que se presentaron en Chicago en el 2019. 


1. Ver la estadistica general del data frame.
2. Elimnar  las columnas PrimaryType, y Date.
3. Transformar la columna Date que es tipo string en una tipo Fecha, use el siguiente metodo de pandas pd.to_datetime(df.Date,format="%m/%d/%Y %I:%M:%S %p")
4. Mostrar los casos totales para cada tipo de crimen de forma ascendente, emplee:
   df.groupby(columna).Date.count()
   
   sort_values()
5. Ordenar los valores por orden alfabetico de Primary type
6. Mostrar de la fila 100 a la 120
6. Realizar una visualización de los datos anteriores.Emplee la libreria  seaborn con un grafico tipo barplot. Ej.
   ax = sns.barplot(x = "contador", y="Primary Type", data = datos)
"""

import pandas as pd

df = pd.read_csv('https://raw.githubusercontent.com/hernansalinas/autogrades/main/Laboratorios_Taller/dataset/Crimes_-_2019.csv')
df

"""Ver la estadistica general del data frame."""

#estadísticas generales del dataframe

estadísticas = df.describe()
estadísticas    #usamos el método describe para obtener los datos generales de las columnas que van a ser de tipo numérico

info_gral = df.info()   #obtenemos informacion de los datos que contiene cada una de las columnas

"""Elimnar las columnas PrimaryType, y Date."""

#ahora, debemos eliminar las columnas  PrimaryType, y Date.

g= df.drop(columns=['Date', 'Primary Type']).copy()     #asigno mi dataframe a una nueva variable, tal que df quede sin los cambios que estoy realizando a partir de acá
g.info()       

#notamos que en efecto ya no se encuentran las columnas que hemos eliminado

"""Transformar la columna Date que es tipo string en una tipo Fecha, use el siguiente metodo de pandas pd.to_datetime(df.Date,format="%m/%d/%Y %I:%M:%S %p")"""

#en este caso, regresamos el df sin la eliminacion de las columnas que habiamos realizado, para hacer el cambio que se pide:

df.Date    #notamos que en efecto hay elementos que vienen de tipo str

df['Date']= pd.to_datetime(df['Date'],format="%m/%d/%Y %H:%M")
df['Date']

"""Mostrar los casos totales para cada tipo de crimen de forma ascendente, emplee: df.groupby(columna).Date.count()

sort_values()
"""

crimenes = df['Primary Type'].dropna()    #con esto podemos ver los diferentes trabajos que hay

tot_cases= df.groupby('Primary Type').Date.count().sort_values()     #aplicando estos métodos podemos determinar las veces que se repite cada uno de los crimenes, y se organiza desde el que menos se repite hasta el que mas se repite
tot_cases

"""Ordenar los valores por orden alfabetico de Primary type"""

#ahora, lo que vamos a hacer es ordenar tot_cases en orden alfabético

tot_cases_ordered= df.groupby('Primary Type').Date.count().sort_index()         #en este caso en lugar de usar el método sort index, vamos a usar el sort value
tot_cases_ordered

"""Mostrar de la fila 100 a la 120"""

##### solo como ejemplo miro la forma en la que puedo determinar un rango determinado de filas correspondientes a las columnas que yo especifique

df[['Description', 'Primary Type']][:2]

#ahora, lo que me piden:

df[100:121]

"""Realizar una visualización de los datos anteriores.Emplee la libreria seaborn con un grafico tipo barplot. Ej. ax = sns.barplot(x = "contador", y="Primary Type", data = datos)"""

df = tot_cases_ordered.reset_index()
df.columns = ['Primary Type', 'Número de casos']    #recordar que esta es la forma en la cual le cambio el nombre a una de las columnas
df

x , y  = df['Primary Type'] ,  df['Número de casos']
len(x), len(y)

#vamos a hacer un gráfico de tot_cases

import seaborn as sns
import matplotlib.pyplot as plt


plt.figure(figsize=(15,10))
ax = sns.barplot(x,y)
plt.title('Tipos de crímenes')
plt.xticks(rotation = 90)    #esto lo hago para rotar las etiquetas del eje x
ax.set_xticklabels(x)


plt.show

"""##Problema 4
- Leer el dataset country_vaccinations.csv y filtrar los datos para Colombia
- Crear un csv con los datos para colombia
- Realizar una comparacion con los paises latinoamericanos de la cantidad de vacunados.
- A traves de mascaras determinar el numero de vacunados en el intervalo [1.5E6, 2.0E6]

"""

import pandas as pd
df=pd.read_csv('https://raw.githubusercontent.com/hernansalinas/autogrades/main/Laboratorios_Taller/dataset/country_vaccinations.csv')
df

df.columns

col =df.loc[df['country'] == 'Colombia']    #obtenemos un dataframe con la informacion filtrada para colombia
col

#ahora, vamos a crear un csv con los datos para colombia

col_csv = col.to_csv()            #por medio de este método podemos convertir archivos de pandas a csv
col_csv

"""Realizar una comparacion con los paises latinoamericanos de la cantidad de vacunados.


"""

lat = df[df['country'].isin(['Colombia', 'Brazil', 'México', 'Ecuador', 'Bolivia', 'Paraguay', 'Nicaragua',
                             'Cuba', 'Argentina', 'Venezuela', 'Uruguay', 'Costa Rica', 'Honduras', 'El Salvador',
                             'Haiti', 'Peru', 'Chile', 'Guatemala', 'República Dominicana', 'Panamá', 'Puerto Rico'])]  
lat

filtro= lat [['country', 'people_vaccinated']]
filtro

vacunados= (filtro.groupby('country').sum()).reset_index()
vacunados

#df.groupby('país')['vacunados', 'natalidad'].sum()   #en caso de que quiera sumar los elementos de cada país correspondiente a varias columnas

x= vacunados['country']
y= vacunados['people_vaccinated']


import seaborn as sns
import matplotlib.pyplot as plt


plt.figure(figsize=(15,10))
ax = sns.barplot(x,y)
plt.title('Personas vacunadas', fontsize = 17)
plt.xticks(rotation = 90, fontsize= 14)    #esto lo hago para rotar las etiquetas del eje x
plt.yticks(fontsize=14)
ax.set_xlabel('country', fontsize= 15)
ax.set_ylabel('Personas vacunadas' ,fontsize= 15)
ax.set_xticklabels(x)


plt.show

"""A traves de mascaras determinar el numero de vacunados en el intervalo [1.5E6, 2.0E6]

"""

#tenemos en cuenta el siguiente dataframe
tabla_gral= df[['country', 'people_vaccinated']].fillna(0)
gral_sum= tabla_gral.groupby('country').sum().copy()                #necesitamos hacer una copia para que los cambios se vean reflejados
gral_sum

#vamos a determinar el numero de vacunados en el intervalo dado

mask = gral_sum['people_vaccinated'].between(1.5e6, 2.0e6)
mask

#para saber el numero de personas en el rango, usamos el metodo sum

mask.sum()

#notamos que 10 paises se encuentran entre el rango de vacunados que es pedido

rango = gral_sum[mask]   #si indexamos el nombre de nuestro dataframe con la mascara que hemos generado, podemos saber los paises que se encuentran en el rango de vacunados que nos piden
rango

rango['people_vaccinated'].max(), rango[rango['people_vaccinated'] == 1945600.0]

